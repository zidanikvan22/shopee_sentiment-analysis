{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Nama** : Zidan Muhammad Ikvan,\n",
        "**Cohort ID** : MC404D5Y0059,\n",
        "**Email** : zidanikvan@gmail.com"
      ],
      "metadata": {
        "id": "WXmRuccFZpYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Library/Package"
      ],
      "metadata": {
        "id": "_dP5uKSsa2nC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LnHJTSoOYwZg",
        "outputId": "2b3db4d9-a239-42bb-eab1-02ac3313cc60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n",
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.21.2 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.1.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.42.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.3.0 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "9f9df723f0e04cb2ac8d9031adac1a0e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install gensim\n",
        "!pip install numpy==1.23.5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Sastrawi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iPQz1n5Y6Ht",
        "outputId": "f5c4bd6d-a1b9-48e5-ecc9-00dc1b48e8c6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n",
            "Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/209.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/209.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Sastrawi\n",
            "Successfully installed Sastrawi-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rj_GYSIIY4iH",
        "outputId": "306b23f1-524b-4e50-9c89-05e64dca2a12"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load dataset"
      ],
      "metadata": {
        "id": "KoE9q9AdcOj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/shopee_reviews_final.csv\")\n",
        "\n",
        "\n",
        "print(df.info())\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSUrOhcVcQPK",
        "outputId": "5afde80f-4324-4b14-c95a-1ed637987275"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10035 entries, 0 to 10034\n",
            "Data columns (total 11 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   userName              10035 non-null  object \n",
            " 1   score                 10035 non-null  int64  \n",
            " 2   content               10034 non-null  object \n",
            " 3   reviewId              1715 non-null   object \n",
            " 4   userImage             1715 non-null   object \n",
            " 5   thumbsUpCount         1715 non-null   float64\n",
            " 6   reviewCreatedVersion  1340 non-null   object \n",
            " 7   at                    1715 non-null   object \n",
            " 8   replyContent          1506 non-null   object \n",
            " 9   repliedAt             1506 non-null   object \n",
            " 10  appVersion            1340 non-null   object \n",
            "dtypes: float64(1), int64(1), object(9)\n",
            "memory usage: 862.5+ KB\n",
            "None\n",
            "                 userName  score  \\\n",
            "0  Eka Simamora## Channel      5   \n",
            "1       Sasmito Alfa (Al)      5   \n",
            "2               Tuti Asih      5   \n",
            "3           Zainal Arifin      5   \n",
            "4               mas yanto      5   \n",
            "\n",
            "                                             content reviewId userImage  \\\n",
            "0                        sangat bermanfaat dan bagus      NaN       NaN   \n",
            "1  sudah ada peningkatan.. semenjak saya komplain...      NaN       NaN   \n",
            "2                      Puas dan happy bersama shopee      NaN       NaN   \n",
            "3               produknya banyak harganya terjangkau      NaN       NaN   \n",
            "4                                              bagus      NaN       NaN   \n",
            "\n",
            "   thumbsUpCount reviewCreatedVersion   at replyContent repliedAt appVersion  \n",
            "0            NaN                  NaN  NaN          NaN       NaN        NaN  \n",
            "1            NaN                  NaN  NaN          NaN       NaN        NaN  \n",
            "2            NaN                  NaN  NaN          NaN       NaN        NaN  \n",
            "3            NaN                  NaN  NaN          NaN       NaN        NaN  \n",
            "4            NaN                  NaN  NaN          NaN       NaN        NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(subset=['content'])"
      ],
      "metadata": {
        "id": "B1Op2p0VlVqR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyisakan hanya kolom yang diperlukan: nama user, skor, dan isi ulasan\n",
        "df = df[['userName', 'score', 'content']]\n",
        "\n",
        "# Menyimpan ulang versi bersih\n",
        "df.to_csv(\"shopee_reviews_cleaned.csv\", index=False)\n",
        "print(df.head())\n",
        "print(f\"Jumlah data akhir: {len(df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bK7Fj6tTcWVq",
        "outputId": "23d7c3de-3629-4a48-cd1a-16e982057a37"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 userName  score  \\\n",
            "0  Eka Simamora## Channel      5   \n",
            "1       Sasmito Alfa (Al)      5   \n",
            "2               Tuti Asih      5   \n",
            "3           Zainal Arifin      5   \n",
            "4               mas yanto      5   \n",
            "\n",
            "                                             content  \n",
            "0                        sangat bermanfaat dan bagus  \n",
            "1  sudah ada peningkatan.. semenjak saya komplain...  \n",
            "2                      Puas dan happy bersama shopee  \n",
            "3               produknya banyak harganya terjangkau  \n",
            "4                                              bagus  \n",
            "Jumlah data akhir: 10034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/shopee_reviews_cleaned.csv\")\n",
        "\n",
        "\n",
        "print(df.info())\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRQN5sHrcqm7",
        "outputId": "c23bf78a-f613-4064-f084-c1b3d7c5a4e0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10034 entries, 0 to 10033\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   userName  10034 non-null  object\n",
            " 1   score     10034 non-null  int64 \n",
            " 2   content   10034 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 235.3+ KB\n",
            "None\n",
            "                 userName  score  \\\n",
            "0  Eka Simamora## Channel      5   \n",
            "1       Sasmito Alfa (Al)      5   \n",
            "2               Tuti Asih      5   \n",
            "3           Zainal Arifin      5   \n",
            "4               mas yanto      5   \n",
            "\n",
            "                                             content  \n",
            "0                        sangat bermanfaat dan bagus  \n",
            "1  sudah ada peningkatan.. semenjak saya komplain...  \n",
            "2                      Puas dan happy bersama shopee  \n",
            "3               produknya banyak harganya terjangkau  \n",
            "4                                              bagus  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing values:\\n\", df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAeaOmchc5Gq",
        "outputId": "8b954b68-fdd7-45aa-ecdc-2fe433d661f9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values:\n",
            " userName    0\n",
            "score       0\n",
            "content     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"jumlah duplikat\", df.duplicated().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvke7w8tc-b6",
        "outputId": "2a194975-5a09-42c0-d3af-bf28c5fdff60"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jumlah duplikat 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing Text"
      ],
      "metadata": {
        "id": "xOjj3jCldNfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load stopwords\n",
        "stop_words = set(stopwords.words('indonesian'))\n",
        "\n",
        "# Inisialisasi stemmer\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "# Fungsi preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    # Hapus angka\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    # Hapus tanda baca\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Hapus emoji dan karakter aneh\n",
        "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
        "    # Hapus whitespace berlebih\n",
        "    text = text.strip()\n",
        "    # Tokenisasi dan hapus stopwords\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    # Stemming\n",
        "    text = ' '.join([stemmer.stem(word) for word in words])\n",
        "    return text\n",
        "\n",
        "# Menerapkan ke kolom content\n",
        "df['clean_content'] = df['content'].apply(preprocess_text)\n",
        "\n",
        "# Cek hasil\n",
        "print(df[['content', 'clean_content']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpm2PiCNdOnp",
        "outputId": "f16954c6-2db4-46b8-eee4-2f454ae4e3bd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             content  \\\n",
            "0                        sangat bermanfaat dan bagus   \n",
            "1  sudah ada peningkatan.. semenjak saya komplain...   \n",
            "2                      Puas dan happy bersama shopee   \n",
            "3               produknya banyak harganya terjangkau   \n",
            "4                                              bagus   \n",
            "\n",
            "                                       clean_content  \n",
            "0                                      manfaat bagus  \n",
            "1  tingkat semenjak komplain kantor pusat bagus k...  \n",
            "2                                  puas happy shopee  \n",
            "3                               produk harga jangkau  \n",
            "4                                              bagus  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pelabelan"
      ],
      "metadata": {
        "id": "nsFuI8zSdh76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menghapus data dengan skor 3\n",
        "df = df[df['score'] != 3]\n",
        "\n",
        "# Menambahkan kolom label\n",
        "df['label'] = df['score'].apply(lambda x: 'positif' if x > 3 else 'negatif')\n",
        "\n",
        "# Cek distribusi label\n",
        "print(df['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KTJhb-6di_J",
        "outputId": "ce2c0543-9f4b-4166-8118-5e9d74b2517e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "positif    7389\n",
            "negatif    2213\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-5bc8dd0a9c4f>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['label'] = df['score'].apply(lambda x: 'positif' if x > 3 else 'negatif')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Splitting dan Ekstraksi Fitur dengan TF-IDF, Word2Vec"
      ],
      "metadata": {
        "id": "2-SAjHVdfRmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X = tfidf.fit_transform(df['clean_content'])\n",
        "y = df['label']\n",
        "\n",
        "# Split data 80:20\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Split data 70:30\n",
        "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "bdx3G5FifS2P"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenisasi\n",
        "tokens = [row.split() for row in df['clean_content']]\n",
        "\n",
        "# Latih Word2Vec\n",
        "w2v_model = Word2Vec(sentences=tokens, vector_size=100, window=5, min_count=2, workers=4, sg=1)"
      ],
      "metadata": {
        "id": "FX5XDM0KzqpV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def avg_vector(text, model, vector_size=100):\n",
        "    words = text.split()\n",
        "    valid_words = [w for w in words if w in model.wv]\n",
        "    if not valid_words:\n",
        "        return np.zeros(vector_size)\n",
        "    return np.mean([model.wv[w] for w in valid_words], axis=0)\n",
        "\n",
        "X_w2v = np.array([avg_vector(text, w2v_model, 100) for text in df['clean_content']])\n",
        "\n",
        "# Data Split\n",
        "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(X_w2v, df['label'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "J8A6ynUuzv-d"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelling"
      ],
      "metadata": {
        "id": "lebfKnrZgxmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_svm = LinearSVC()\n",
        "model_svm.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred_svm = model_svm.predict(X_test)\n",
        "\n",
        "# Evaluasi\n",
        "print(\"Akurasi testing SVM:\", accuracy_score(y_test, y_pred_svm))\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "\n",
        "y_train_pred = model_svm.predict(X_train)\n",
        "\n",
        "# Evaluasi akurasi training\n",
        "print(\"Akurasi Training SVM:\", accuracy_score(y_train, y_train_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-oTJYhngzGf",
        "outputId": "5ce16f8a-9565-4566-d9b4-a0a1102cdf16"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi testing SVM: 0.9125455491931286\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.83      0.77      0.80       443\n",
            "     positif       0.93      0.95      0.94      1478\n",
            "\n",
            "    accuracy                           0.91      1921\n",
            "   macro avg       0.88      0.86      0.87      1921\n",
            "weighted avg       0.91      0.91      0.91      1921\n",
            "\n",
            "Akurasi Training SVM: 0.9714880874886083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inisialisasi model\n",
        "model_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Training (gunakan X_train_1 dan y_train_1 dari split 70:30)\n",
        "model_rf.fit(X_train_1, y_train_1)\n",
        "\n",
        "# Prediksi (gunakan X_test_1 dari split 70:30)\n",
        "y_pred_rf = model_rf.predict(X_test_1)\n",
        "y_train_pred_rf = model_rf.predict(X_train_1)\n",
        "\n",
        "# Evaluasi (gunakan y_test_1 dan y_train_1 dari split 70:30)\n",
        "print(\"\\n=== Hasil dengan Pembagian 70/30 ===\")\n",
        "print(\"Akurasi Training RF:\", accuracy_score(y_train_1, y_train_pred_rf))\n",
        "print(\"Akurasi Testing RF:\", accuracy_score(y_test_1, y_pred_rf))\n",
        "print(\"\\nLaporan Klasifikasi:\")\n",
        "print(classification_report(y_test_1, y_pred_rf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2Q8SieG3b1D",
        "outputId": "0a17ef87-6f9f-4a24-ff5c-1e44fd8c990e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Hasil dengan Pembagian 70/30 ===\n",
            "Akurasi Training RF: 0.9953875911322719\n",
            "Akurasi Testing RF: 0.8986463033668864\n",
            "\n",
            "Laporan Klasifikasi:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.79      0.76      0.78       664\n",
            "     positif       0.93      0.94      0.93      2217\n",
            "\n",
            "    accuracy                           0.90      2881\n",
            "   macro avg       0.86      0.85      0.86      2881\n",
            "weighted avg       0.90      0.90      0.90      2881\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelling (Random Forest)\n",
        "model_rf_w2v = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model_rf_w2v.fit(X_train_w2v, y_train_w2v)\n",
        "\n",
        "# Evaluasi\n",
        "y_pred_rf_w2v = model_rf_w2v.predict(X_test_w2v)\n",
        "y_train_pred_rf_w2v = model_rf_w2v.predict(X_train_w2v)\n",
        "\n",
        "print(\"Akurasi Training RF + Word2Vec:\", accuracy_score(y_train_w2v, y_train_pred_rf_w2v))\n",
        "print(\"Akurasi Testing RF + Word2Vec:\", accuracy_score(y_test_w2v, y_pred_rf_w2v))\n",
        "print(classification_report(y_test_w2v, y_pred_rf_w2v))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5pB0Cs0z3aB",
        "outputId": "3149c756-0fb2-433e-eb4e-95db0ff8e4a5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi Training RF + Word2Vec: 0.9954433016534305\n",
            "Akurasi Testing RF + Word2Vec: 0.8833940655908381\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.74      0.78      0.76       446\n",
            "     positif       0.93      0.92      0.92      1475\n",
            "\n",
            "    accuracy                           0.88      1921\n",
            "   macro avg       0.83      0.85      0.84      1921\n",
            "weighted avg       0.89      0.88      0.88      1921\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive bayes\n",
        "model_nb = MultinomialNB()\n",
        "model_nb.fit(X_train, y_train)\n",
        "\n",
        "y_pred_nb = model_nb.predict(X_test)\n",
        "y_train_pred_nb = model_nb.predict(X_train)\n",
        "\n",
        "print(\"Akurasi Training NB + TF-IDF:\", accuracy_score(y_train, y_train_pred_nb))\n",
        "print(\"Akurasi Testing NB + TF-IDF:\", accuracy_score(y_test, y_pred_nb))\n",
        "print(classification_report(y_test, y_pred_nb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYGFSrUG5cgV",
        "outputId": "bbcf96be-7f78-49e7-8def-95d3abaafb48"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi Training NB + TF-IDF: 0.9191511521937248\n",
            "Akurasi Testing NB + TF-IDF: 0.9000520562207184\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     negatif       0.86      0.67      0.76       443\n",
            "     positif       0.91      0.97      0.94      1478\n",
            "\n",
            "    accuracy                           0.90      1921\n",
            "   macro avg       0.89      0.82      0.85      1921\n",
            "weighted avg       0.90      0.90      0.90      1921\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "rz37l8KWBUpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh inferensi pada data baru\n",
        "sample_review = [\"Shopee adalah aplikasi belanja yang sangat baik!\", \"Produk sangat buruk, tidak sesuai ekspektasi.\"]\n",
        "sample_tfidf = tfidf.transform(sample_review)\n",
        "predictions = model_nb.predict(sample_tfidf)\n",
        "\n",
        "# Output hasil inferensi\n",
        "print(\"Hasil Prediksi:\", predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9a13BtE3RcL",
        "outputId": "01c0a5dd-d3b2-4eac-e217-bee08ca2dc56"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil Prediksi: ['positif' 'positif']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh inferensi pada data baru\n",
        "sample_review = [\"Shopee adalah aplikasi belanja yang sangat baik!\", \"Produk sangat buruk, tidak sesuai ekspektasi.\"]\n",
        "sample_tfidf = tfidf.transform(sample_review)\n",
        "predictions = model_rf.predict(sample_tfidf)\n",
        "\n",
        "# Output hasil inferensi\n",
        "print(\"Hasil Prediksi:\", predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbzKd4yPCM8c",
        "outputId": "6ce81251-2ffc-450b-be51-9b196297bcf4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil Prediksi: ['positif' 'negatif']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh inferensi pada data baru\n",
        "sample_review = [\"Shopee adalah aplikasi belanja yang sangat baik!\", \"Produk sangat buruk, tidak sesuai ekspektasi.\"]\n",
        "sample_tfidf = tfidf.transform(sample_review)\n",
        "predictions = model_svm.predict(sample_tfidf)\n",
        "\n",
        "# Output hasil inferensi )\n",
        "print(\"Hasil Prediksi:\", predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2mNDnwyFfLE",
        "outputId": "32817c35-afbc-46bc-fbe9-3b4fa4b8e88b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil Prediksi: ['positif' 'positif']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh inferensi pada data baru\n",
        "sample_review = [\"Shopee adalah aplikasi belanja yang sangat baik!\", \"Produk sangat buruk, tidak sesuai ekspektasi.\"]\n",
        "\n",
        "# Preprocessing teks (sesuai clean_content)\n",
        "sample_clean = [text.lower().replace(\".\", \"\").replace(\"!\", \"\") for text in sample_review]\n",
        "\n",
        "# Konversi teks ke vektor rata-rata Word2Vec\n",
        "sample_vectors = np.array([avg_vector(text, w2v_model, 100) for text in sample_clean])\n",
        "\n",
        "# Prediksi dengan model Random Forest yang sudah dilatih\n",
        "predictions = model_rf_w2v.predict(sample_vectors)\n",
        "\n",
        "print(\"Hasil Prediksi:\", predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N3ALOWXLKlU",
        "outputId": "2c5b2764-3ac4-49c3-9782-003f4571ae28"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil Prediksi: ['positif' 'positif']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kesimpulan"
      ],
      "metadata": {
        "id": "LEZSD25HqPWt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Model terbaik secara keseluruhan dalam hal akurasi dan konsistensi prediksi pada data baru adalah Random Forest dengan fitur TF-IDF, karena berhasil mengenali kelas negatif dengan lebih akurat pada inferensi nyata.\n",
        "\n",
        "- SVM dengan TF-IDF menunjukkan performa tinggi pada metrik akurasi dan f1-score, tetapi agak kurang dalam mengenali sentimen negatif.\n",
        "\n",
        "- Model berbasis Word2Vec juga menunjukkan hasil yang kompetitif, namun tidak memberikan keunggulan signifikan dibandingkan pendekatan TF-IDF.\n",
        "\n",
        "- Kelemahan utama dari semua model adalah dalam mendeteksi kelas minoritas (negatif), sehingga di proyek yang akan datang perlu dilakukan penyeimbangan data atau penggunaan teknik peningkatan minoritas seperti SMOTE."
      ],
      "metadata": {
        "id": "biKWsb1LqkqP"
      }
    }
  ]
}