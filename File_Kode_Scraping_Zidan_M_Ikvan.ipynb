{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Nama** : Zidan Muhammad Ikvan,\n",
        "**Cohort ID** : MC404D5Y0059,\n",
        "**Email** : zidanikvan@gmail.com"
      ],
      "metadata": {
        "id": "WXmRuccFZpYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Library/Package"
      ],
      "metadata": {
        "id": "_dP5uKSsa2nC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-play-scraper pandas tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWMAC9NRY2xZ",
        "outputId": "eba052a5-7452-41c9-c8db-e5fb99a5e3df"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-play-scraper\n",
            "  Downloading google_play_scraper-1.2.7-py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading google_play_scraper-1.2.7-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: google-play-scraper\n",
            "Successfully installed google-play-scraper-1.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "from google_play_scraper import Sort, reviews\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "Rj_GYSIIY4iH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scraping Dataset"
      ],
      "metadata": {
        "id": "w0rlvoQYbOhw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_reviews = []\n",
        "token = None\n",
        "target_total = 11000\n",
        "\n",
        "print(\"Mulai scraping data...\")\n",
        "\n",
        "with tqdm(total=target_total) as pbar:\n",
        "    while len(all_reviews) < target_total:\n",
        "        result, token = reviews(\n",
        "            'com.shopee.id',\n",
        "            lang='id',\n",
        "            country='id',\n",
        "            sort=Sort.NEWEST,\n",
        "            count=200,\n",
        "            continuation_token=token\n",
        "        )\n",
        "        all_reviews.extend(result)\n",
        "        pbar.update(len(result))\n",
        "        time.sleep(1)  # menghindari diblokir oleh server\n",
        "\n",
        "# Konversi ke DataFrame\n",
        "df = pd.DataFrame(all_reviews)\n",
        "\n",
        "# Hapus duplikat berdasarkan isi review\n",
        "df.drop_duplicates(subset='content', inplace=True)\n",
        "df.dropna(subset=['content'], inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Tampilkan jumlah akhir\n",
        "print(f\"Jumlah data setelah bersih: {len(df)}\")\n",
        "\n",
        "# Simpan ke file\n",
        "df[['userName', 'score', 'content']].to_csv(\"shopee_reviews_clean.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppyOKLeQbRGS",
        "outputId": "276b4363-a52b-49b1-caf4-a7e5fa29e263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mulai scraping data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11000/11000 [01:08<00:00, 159.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah data setelah bersih: 8320\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data sebelumnya\n",
        "df_existing = pd.read_csv(\"shopee_reviews_clean.csv\")\n",
        "existing_contents = set(df_existing['content'])\n",
        "\n",
        "# Lanjut dari token terakhir (set awal = None)\n",
        "token = None\n",
        "new_reviews = []\n",
        "needed = 10000 - len(df_existing)\n",
        "\n",
        "print(f\"Scraping tambahan untuk {needed} review...\")\n",
        "\n",
        "with tqdm(total=needed) as pbar:\n",
        "    while len(new_reviews) < needed:\n",
        "        result, token = reviews(\n",
        "            'com.shopee.id',\n",
        "            lang='id',\n",
        "            country='id',\n",
        "            sort=Sort.NEWEST,\n",
        "            count=200,\n",
        "            continuation_token=token\n",
        "        )\n",
        "        for r in result:\n",
        "            if r['content'] not in existing_contents:\n",
        "                new_reviews.append(r)\n",
        "                existing_contents.add(r['content'])\n",
        "        pbar.update(len(result))\n",
        "        time.sleep(1)\n",
        "\n",
        "# Menggabungkan data\n",
        "df_new = pd.DataFrame(new_reviews)\n",
        "df_combined = pd.concat([df_existing, df_new], ignore_index=True)\n",
        "\n",
        "# Simpan lagi\n",
        "df_combined.to_csv(\"shopee_reviews_final.csv\", index=False)\n",
        "print(f\"Jumlah data akhir: {len(df_combined)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RU0LPtLbq1r",
        "outputId": "42558dfa-1ec1-4e90-ffc2-4d628e3c13d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping tambahan untuk 1680 review...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13400it [01:21, 164.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah data akhir: 10035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}